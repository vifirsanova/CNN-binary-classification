{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Classifier",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ODshDOGPLp-q"
      },
      "source": [
        "#Библиотеки"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y2wyIRpw3RRm",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "388e585e-695d-4082-b887-e83288861083"
      },
      "source": [
        "from google.colab import files\n",
        "import numpy as np\n",
        "from numpy import random\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "from tensorflow.keras import utils\n",
        "\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout, SpatialDropout1D, BatchNormalization, Embedding, Flatten, Activation, SimpleRNN\n",
        "from tensorflow.python.keras.optimizers import Adam, RMSprop\n",
        "\n",
        "from keras.preprocessing.text import Tokenizer, text_to_word_sequence\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kvf0nodwLuKJ"
      },
      "source": [
        "#Предобработка данных"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HxmTzbq3TmJW"
      },
      "source": [
        "# Токенизатор из библиотеки Keras\n",
        "\n",
        "tokenizer = Tokenizer(num_words=20000, filters='!\"#$%&()*+,-./:;,<=>?@[\\\\]^_`{|}~\\t\\n0123456789', lower=True, split=' ', char_level=False)\n",
        "\n",
        "# Метод обрабатывает тексты и собирает словарь\n",
        "\n",
        "tokenizer.fit_on_texts(train)\n",
        "\n",
        "# Частотные индексы (ранги слов по частоте встречаемости)\n",
        "\n",
        "items = list(tokenizer.word_index.items())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7bqkBm_VMOys"
      },
      "source": [
        "```\r\n",
        "Образец словаря \r\n",
        "\r\n",
        "[('днем', 1001), ('живут', 1002), ('одновременно', 1003), ('новые', 1004), ('вернулся', 1005), ('решение', 1006), ('действия', 1007), \r\n",
        "('сделали', 1008), ('зато', 1009), ('человеку', 1010), ('телефона', 1011), ('путь', 1012), ('найден', 1013), ('кровати', 1014), \r\n",
        "('честно', 1015), ('больно', 1016), ('ж', 1017), ('буквально', 1018), ('сознания', 1019), ('пропал', 1020), ('плиз', 1021), \r\n",
        "('идёт', 1022), ('полу', 1023), ('видели', 1024), ('знакомых', 1025), ('ходит', 1026), ('получить', 1027), ('знать', 1028), \r\n",
        "('ушла', 1029), ('iz', 1030), ('ук', 1031), ('nкто', 1032), ('сильнее', 1033), ('нашу', 1034), ('полный', 1035), ('нашёл', 1036), \r\n",
        "('разных', 1037), ('узнал', 1038), ('бесплатно', 1039), ('комнаты', 1040), ('поехали', 1041),  ('памяти', 1042), ('забыл', 1043), \r\n",
        "('ощущения', 1044), ('могли', 1045), ('думала', 1046), ('nтак', 1047), ('конца', 1048), ('количество', 1049), ('большая', 1050), \r\n",
        "('source', 1051), ('предложил', 1052), ('сходить', 1053), ('звоните', 1054), ('уйти', 1055), ('км', 1056), ('пришли', 1057)]\r\n",
        "\r\n",
        "Размер словаря - 137802 слов\r\n",
        "```\r\n",
        "\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oAbeKuj8XvOV"
      },
      "source": [
        "# Тексты приводятся к виду последовательностей чисел\n",
        "# в соответствии с индексами обучающего словаря\n",
        "\n",
        "trainIdx = tokenizer.texts_to_sequences(train)\n",
        "testIdx = tokenizer.texts_to_sequences(test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SF7X4JKYOIS5"
      },
      "source": [
        "#Обучение модели"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "stwZbQWT6pA4"
      },
      "source": [
        "# Архитектура сверточной нейросети\n",
        "# Модель, основанная на Bag-of-Words\n",
        "\n",
        "model = Sequential()\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dense(200, input_dim=maxWordsCount, activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dense(2, activation='softmax'))\n",
        "\n",
        "model.compile(optimizer='adam',\n",
        "                loss='categorical_crossentropy',\n",
        "                metrics=['accuracy', precision, recall])\n",
        "\n",
        "history = model.fit(xTrain01,\n",
        "                      yTrain,\n",
        "                      epochs=20,\n",
        "                      batch_size=200,\n",
        "                      validation_data=(xTest01, yTest))\n",
        "                      callbacks=[checkpoint])\n",
        "\n",
        "plt.plot(history.history['accuracy'],\n",
        "         label='Доля верных ответов на обучающей выборке')\n",
        "plt.plot(history.history['val_accuracy'],\n",
        "         label='Доля верных ответов на тестовой выборке')\n",
        "plt.xlabel('Эпоха обучения')\n",
        "plt.ylabel('Доля верных ответов')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sjfKM7iVk3aj"
      },
      "source": [
        "# Модель c Embedding-слоем \n",
        "\n",
        "modelE = Sequential()\n",
        "modelE.add(Embedding(maxWordsCount, 30, input_length=xLen)) #30-мерное пространство\n",
        "modelE.add(SpatialDropout1D(0.25))\n",
        "modelE.add(Flatten())\n",
        "modelE.add(BatchNormalization())\n",
        "modelE.add(Dense(200, activation='relu'))\n",
        "modelE.add(Dropout(0.25))\n",
        "modelE.add(BatchNormalization())\n",
        "modelE.add(Dense(2, activation='softmax'))\n",
        "\n",
        "modelE.compile(optimizer='adam',\n",
        "                loss='categorical_crossentropy',\n",
        "                metrics=['accuracy', precision, recall])\n",
        "\n",
        "history = modelE.fit(xTrain,\n",
        "                      yTrain,\n",
        "                      epochs=20,\n",
        "                      batch_size=200,\n",
        "                      validation_data=(xTest, yTest))\n",
        "\n",
        "plt.plot(history.history['accuracy'],\n",
        "         label='Доля верных ответов на обучающей выборке')\n",
        "plt.plot(history.history['val_accuracy'],\n",
        "         label='Доля верных ответов на тестовой выборке')\n",
        "plt.xlabel('Эпоха обучения')\n",
        "plt.ylabel('Доля верных ответов')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}