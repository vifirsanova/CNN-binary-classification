{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Classifier",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ODshDOGPLp-q"
      },
      "source": [
        "#Libraries (Библиотеки)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y2wyIRpw3RRm"
      },
      "source": [
        "from google.colab import files\n",
        "import numpy as np\n",
        "from numpy import random\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "from tensorflow.keras import utils\n",
        "\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout, SpatialDropout1D, BatchNormalization, Embedding, Flatten, Activation, SimpleRNN\n",
        "from tensorflow.python.keras.optimizers import Adam, RMSprop\n",
        "\n",
        "from keras.preprocessing.text import Tokenizer, text_to_word_sequence\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kvf0nodwLuKJ"
      },
      "source": [
        "#Data preprocessing (Предобработка данных)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HxmTzbq3TmJW"
      },
      "source": [
        "# Keras Tokenizer (Токенизатор из библиотеки Keras)\n",
        "\n",
        "tokenizer = Tokenizer(num_words=20000, filters='!\"#$%&()*+,-./:;,<=>?@[\\\\]^_`{|}~\\t\\n0123456789', lower=True, split=' ', char_level=False)\n",
        "\n",
        "# Method processes texts and collect a dictionary (Метод обрабатывает тексты и собирает словарь)\n",
        "\n",
        "tokenizer.fit_on_texts(train)\n",
        "\n",
        "# Frequency indexes - word ranking according to the word frequency (Частотные индексы - ранжирование слов по частоте встречаемости)\n",
        "\n",
        "items = list(tokenizer.word_index.items())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7bqkBm_VMOys"
      },
      "source": [
        "```\r\n",
        "Dictionary sample (Образец словаря) 1001-1029\r\n",
        "\r\n",
        "[('днем', 1001), ('живут', 1002), ('одновременно', 1003), ('новые', 1004), ('вернулся', 1005), ('решение', 1006), \r\n",
        "('действия', 1007), ('сделали', 1008), ('зато', 1009), ('человеку', 1010), ('телефона', 1011), ('путь', 1012), \r\n",
        "('найден', 1013), ('кровати', 1014), ('честно', 1015), ('больно', 1016), ('ж', 1017), ('буквально', 1018), \r\n",
        "('сознания', 1019), ('пропал', 1020), ('плиз', 1021), ('идёт', 1022), ('полу', 1023), ('видели', 1024), \r\n",
        "('знакомых', 1025), ('ходит', 1026), ('получить', 1027), ('знать', 1028), ('ушла', 1029)]\r\n",
        "\r\n",
        "The volume of the dictionary is (Размер словаря составляет) 137802 слов\r\n",
        "```\r\n",
        "\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oAbeKuj8XvOV"
      },
      "source": [
        "# Texts are transformed into digital sequences (Тексты приводятся к виду последовательностей чисел)\n",
        "# according to the indexes in the training dictionary (в соответствии с индексами обучающего словаря)\n",
        "\n",
        "trainIdx = tokenizer.texts_to_sequences(train)\n",
        "testIdx = tokenizer.texts_to_sequences(test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SF7X4JKYOIS5"
      },
      "source": [
        "#Model training (Обучение модели)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "stwZbQWT6pA4"
      },
      "source": [
        "# The architecture of ConvNet(Архитектура сверточной нейросети)\n",
        "# Bag-of-Words based model (Модель, основанная на Bag-of-Words)\n",
        "\n",
        "model = Sequential()\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dense(200, input_dim=maxWordsCount, activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dense(2, activation='softmax'))\n",
        "\n",
        "model.compile(optimizer='adam',\n",
        "                loss='categorical_crossentropy',\n",
        "                metrics=['accuracy', precision, recall])\n",
        "\n",
        "history = model.fit(xTrain01,\n",
        "                      yTrain,\n",
        "                      epochs=20,\n",
        "                      batch_size=200,\n",
        "                      validation_data=(xTest01, yTest))\n",
        "                      callbacks=[checkpoint])\n",
        "\n",
        "plt.plot(history.history['accuracy'],\n",
        "         label='Доля верных ответов на обучающей выборке')\n",
        "plt.plot(history.history['val_accuracy'],\n",
        "         label='Доля верных ответов на тестовой выборке')\n",
        "plt.xlabel('Эпоха обучения')\n",
        "plt.ylabel('Доля верных ответов')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sjfKM7iVk3aj"
      },
      "source": [
        "# The model with Embeddings-layer (Модель c Embedding-слоем)\n",
        "\n",
        "modelE = Sequential()\n",
        "modelE.add(Embedding(maxWordsCount, 30, input_length=xLen)) #30-мерное пространство\n",
        "modelE.add(SpatialDropout1D(0.25))\n",
        "modelE.add(Flatten())\n",
        "modelE.add(BatchNormalization())\n",
        "modelE.add(Dense(200, activation='relu'))\n",
        "modelE.add(Dropout(0.25))\n",
        "modelE.add(BatchNormalization())\n",
        "modelE.add(Dense(2, activation='softmax'))\n",
        "\n",
        "modelE.compile(optimizer='adam',\n",
        "                loss='categorical_crossentropy',\n",
        "                metrics=['accuracy', precision, recall])\n",
        "\n",
        "history = modelE.fit(xTrain,\n",
        "                      yTrain,\n",
        "                      epochs=20,\n",
        "                      batch_size=200,\n",
        "                      validation_data=(xTest, yTest))\n",
        "\n",
        "plt.plot(history.history['accuracy'],\n",
        "         label='Доля верных ответов на обучающей выборке')\n",
        "plt.plot(history.history['val_accuracy'],\n",
        "         label='Доля верных ответов на тестовой выборке')\n",
        "plt.xlabel('Эпоха обучения')\n",
        "plt.ylabel('Доля верных ответов')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
